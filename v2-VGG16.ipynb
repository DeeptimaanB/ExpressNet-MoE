{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de57fb8-f88c-4674-b3d6-b383ef2d9e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 15:07:45.666412: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-26 15:07:46.234971: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a41117-6039-467d-a39c-ae54ad725af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'FER-2013/test'  \n",
    "train_dir = 'FER-2013/train'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a80a85-8a36-43c9-a4c6-485f3d243f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    brightness_range =[0.8,1.2],\n",
    "    shear_range = 0.15,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "datagen_val = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7bb2010-7e1e-4f4a-a466-877b9fcad21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen_train.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(48, 48),    # FER images are typically 48x48\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = datagen_val.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(48, 48),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43be9da2-cff2-46cf-8291-c50496a74470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 15:07:49.581461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11541 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:19:00.0, compute capability: 6.1\n",
      "2024-12-26 15:07:49.582050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 11541 MB memory:  -> device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:1a:00.0, compute capability: 6.1\n",
      "2024-12-26 15:07:49.582533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 11541 MB memory:  -> device: 2, name: NVIDIA TITAN Xp, pci bus id: 0000:67:00.0, compute capability: 6.1\n",
      "2024-12-26 15:07:49.583044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 11533 MB memory:  -> device: 3, name: NVIDIA TITAN Xp, pci bus id: 0000:68:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 512)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 256)               1024      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14881351 (56.77 MB)\n",
      "Trainable params: 7245319 (27.64 MB)\n",
      "Non-trainable params: 7636032 (29.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Load VGG16 pre-trained on ImageNet, without the top fully connected layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Freeze all layers except the last 3\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the emotion detection model\n",
    "model = Sequential([\n",
    "    base_model,  # Pre-trained VGG16 as the base\n",
    "    GlobalAveragePooling2D(),  # Replace Flatten with GAP\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(7, activation='softmax')  # 7 classes for emotion detection\n",
    "])\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5951bc99-c4d4-466c-b115-0cab26c0a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5c2c0-2f42-4bed-80ab-f4a5a99aa32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 15:07:56.360344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-12-26 15:07:56.847957: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb67004ace0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-26 15:07:56.847987: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-12-26 15:07:56.847993: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-12-26 15:07:56.848000: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-12-26 15:07:56.848004: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-12-26 15:07:56.852286: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-26 15:07:56.869545: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:543] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.8\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2024-12-26 15:07:56.982301: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 39s 81ms/step - loss: 3.3748 - accuracy: 0.2704 - val_loss: 2.6141 - val_accuracy: 0.2907\n",
      "Epoch 2/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.9981 - accuracy: 0.3482 - val_loss: 1.8565 - val_accuracy: 0.3894\n",
      "Epoch 3/500\n",
      "449/449 [==============================] - 36s 80ms/step - loss: 1.7350 - accuracy: 0.3781 - val_loss: 1.7791 - val_accuracy: 0.3817\n",
      "Epoch 4/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.6289 - accuracy: 0.4010 - val_loss: 1.7434 - val_accuracy: 0.4086\n",
      "Epoch 5/500\n",
      "449/449 [==============================] - 36s 80ms/step - loss: 1.5846 - accuracy: 0.4082 - val_loss: 1.4749 - val_accuracy: 0.4553\n",
      "Epoch 6/500\n",
      "449/449 [==============================] - 37s 82ms/step - loss: 1.5511 - accuracy: 0.4214 - val_loss: 1.5866 - val_accuracy: 0.4092\n",
      "Epoch 7/500\n",
      "449/449 [==============================] - 36s 80ms/step - loss: 1.5329 - accuracy: 0.4289 - val_loss: 1.4972 - val_accuracy: 0.4617\n",
      "Epoch 8/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.5186 - accuracy: 0.4307 - val_loss: 1.4594 - val_accuracy: 0.4508\n",
      "Epoch 9/500\n",
      "449/449 [==============================] - 35s 79ms/step - loss: 1.5194 - accuracy: 0.4314 - val_loss: 1.5406 - val_accuracy: 0.4366\n",
      "Epoch 10/500\n",
      "449/449 [==============================] - 37s 82ms/step - loss: 1.5085 - accuracy: 0.4371 - val_loss: 1.5471 - val_accuracy: 0.4504\n",
      "Epoch 11/500\n",
      "449/449 [==============================] - 37s 82ms/step - loss: 1.4928 - accuracy: 0.4421 - val_loss: 1.4190 - val_accuracy: 0.4817\n",
      "Epoch 12/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.4784 - accuracy: 0.4474 - val_loss: 1.4184 - val_accuracy: 0.4706\n",
      "Epoch 13/500\n",
      "449/449 [==============================] - 36s 80ms/step - loss: 1.4634 - accuracy: 0.4555 - val_loss: 1.3737 - val_accuracy: 0.4865\n",
      "Epoch 14/500\n",
      "449/449 [==============================] - 37s 82ms/step - loss: 1.4645 - accuracy: 0.4572 - val_loss: 1.3893 - val_accuracy: 0.4752\n",
      "Epoch 15/500\n",
      "449/449 [==============================] - 37s 81ms/step - loss: 1.4566 - accuracy: 0.4600 - val_loss: 1.3957 - val_accuracy: 0.4792\n",
      "Epoch 16/500\n",
      "449/449 [==============================] - 36s 79ms/step - loss: 1.4552 - accuracy: 0.4596 - val_loss: 1.3874 - val_accuracy: 0.4841\n",
      "Epoch 17/500\n",
      "449/449 [==============================] - 36s 80ms/step - loss: 1.4428 - accuracy: 0.4653 - val_loss: 1.3453 - val_accuracy: 0.4932\n",
      "Epoch 18/500\n",
      "449/449 [==============================] - 36s 79ms/step - loss: 1.4328 - accuracy: 0.4635 - val_loss: 1.3388 - val_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.4368 - accuracy: 0.4643 - val_loss: 1.3342 - val_accuracy: 0.4992\n",
      "Epoch 20/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.4321 - accuracy: 0.4686 - val_loss: 1.3581 - val_accuracy: 0.4844\n",
      "Epoch 21/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.4187 - accuracy: 0.4718 - val_loss: 1.3682 - val_accuracy: 0.4969\n",
      "Epoch 22/500\n",
      "449/449 [==============================] - 35s 79ms/step - loss: 1.4157 - accuracy: 0.4722 - val_loss: 1.3110 - val_accuracy: 0.5127\n",
      "Epoch 23/500\n",
      "449/449 [==============================] - 37s 81ms/step - loss: 1.4118 - accuracy: 0.4766 - val_loss: 1.3354 - val_accuracy: 0.5089\n",
      "Epoch 24/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.4046 - accuracy: 0.4767 - val_loss: 1.5385 - val_accuracy: 0.4287\n",
      "Epoch 25/500\n",
      "449/449 [==============================] - 37s 81ms/step - loss: 1.4040 - accuracy: 0.4822 - val_loss: 1.4640 - val_accuracy: 0.4546\n",
      "Epoch 26/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.3967 - accuracy: 0.4855 - val_loss: 1.2983 - val_accuracy: 0.5227\n",
      "Epoch 27/500\n",
      "449/449 [==============================] - 36s 80ms/step - loss: 1.3908 - accuracy: 0.4847 - val_loss: 1.3171 - val_accuracy: 0.5128\n",
      "Epoch 28/500\n",
      "449/449 [==============================] - 37s 82ms/step - loss: 1.3864 - accuracy: 0.4874 - val_loss: 1.2976 - val_accuracy: 0.5166\n",
      "Epoch 29/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.3869 - accuracy: 0.4869 - val_loss: 1.5576 - val_accuracy: 0.4179\n",
      "Epoch 30/500\n",
      "449/449 [==============================] - 36s 80ms/step - loss: 1.4398 - accuracy: 0.4658 - val_loss: 1.3450 - val_accuracy: 0.5040\n",
      "Epoch 31/500\n",
      "449/449 [==============================] - 36s 79ms/step - loss: 1.4083 - accuracy: 0.4794 - val_loss: 1.2836 - val_accuracy: 0.5265\n",
      "Epoch 32/500\n",
      "449/449 [==============================] - 36s 79ms/step - loss: 1.3821 - accuracy: 0.4857 - val_loss: 1.2948 - val_accuracy: 0.5192\n",
      "Epoch 33/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.3735 - accuracy: 0.4919 - val_loss: 1.2997 - val_accuracy: 0.5153\n",
      "Epoch 34/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.3725 - accuracy: 0.4960 - val_loss: 1.3589 - val_accuracy: 0.4889\n",
      "Epoch 35/500\n",
      "449/449 [==============================] - 36s 81ms/step - loss: 1.3662 - accuracy: 0.4985 - val_loss: 1.3284 - val_accuracy: 0.5125\n",
      "Epoch 36/500\n",
      "123/449 [=======>......................] - ETA: 24s - loss: 1.3555 - accuracy: 0.5066"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=500,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bdf892-4d2f-4e80-b533-df7a2625e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"v2-VGG16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15d0da-96af-42d2-beb7-5b8541e6d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract data from history\n",
    "history_dict = history.history\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "\n",
    "# Get the number of epochs\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, accuracy, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'r-', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5a0e8-309a-4556-86ac-e81b192614ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-p39-tf2",
   "language": "python",
   "name": "venv-p39-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
